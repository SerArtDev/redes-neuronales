{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMUshJcgeO2xFoOeP6OldJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerArtDev/redes-neuronales/blob/main/redes_neuronales_otras_redes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otros Tipos de Redes\n",
        "\n",
        "Además de las redes de regresión y clasificación, existen otras más optimas para otros casos.\n",
        "\n"
      ],
      "metadata": {
        "id": "DME6Bmx7CsAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red Neuronal Convolucional (CNN)\n",
        "Esta está especializada en reconocimiento de imágenes para clasificarlas o detectar objetos. La clasificación de imágenes se puede mediante una red neuronal de clasificación, pero es menos óptima que la covolucional, ya que esta última aplica procesado previo a pasar por la red a las imágenes. Estos preprocesados tienen como objetivo resaltar características de la imagen, resaltar bordes, hacer más claros los objetos de interés y reducir los parámetros de entrada a la red, reduciendo así la probabilidad de overfitting.\n",
        "\n",
        "Una arquitectura típica para un modelos de CNN es el siguiente:\n",
        "\n",
        "Imagen -> Capa de convolución > Capa de agrupamiento > Capa de convolución > Capa de agrupamiento > Red Neuronal secuencial densa > Capa de salida\n",
        "\n",
        "Mientras que en una red neuronal de clasificación tradicional la imagen se convierte en un vector de n x 1, donde n es la cantidad de pixeles, el cual es pasado a la capa de entrada, en una red convolucional se pasa a la capa de entrada una matriz de la forma n x m x 3, donde n y m son los las lados de las imágenes y 3 es por cada capa de color (RGB).\n",
        "\n",
        "La convolución consiste en aplicar un producto punto entre cada una de las capas RGB de la imagen y una matriz filtro (o kernel). Este filtro es el que permite realzar cosas como los bordes de elementos, realzar colores, etc. De esta forma, la red detecta de mejor forma estas características de la imagen. Adicional a esto, en la red convolucional también se aplica una función de activación a cada pixel. Típicamente se usa la función ReLU.\n",
        "\n",
        "La capa de agrupamiento se encarga en reducir la cantidad de datos que serán propagados por la red sin perder las características importantes de la imagen. Existen dos formas principales de lograr esto: max pooling y average pooling.\n",
        "El primero consiste en tomar grupos de pixeles de ixj dimensiones, tomar el valor más alto de estos y representarlos en un solo pixel, descartando a los otros. Average pooling consiste en sacar el valor promedio de este grupo de pixeles y representarlo también en un solo pixel. De estas dos formas, si, por ejemplo, tenemos una imagen de 16x16 y tomamos grupos de 2x2, obtendremos una imagen de 8x8 pixeles, reduciendo significativamente la cantidad de datos que entrará a la red.\n"
      ],
      "metadata": {
        "id": "hPeuScVPdOFa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ReMfwlypCl5G"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "# Vamos a usar un set de datos con imágenes de distintos números para ser categorizados\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estos datos cuentan con un set de entrenamiento y otro de verificación\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Cambiamos la forma de los datos\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# Normalizamos los datos para que los pixeles tengan valores de 0 a 1.\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "fZYW8Di8MqF5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La variable de salida está categorizada de 0 a 9, pero esto debe ser\n",
        "# convertido para trabajar en una red neuronal\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "# Se obtienen la cantidad de clases\n",
        "num_classes = y_test.shape[1]"
      ],
      "metadata": {
        "id": "e7DCgKlsM-_1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo de red convolucional\n",
        "model = Sequential()\n",
        "# Se crea la capa convolucional de 16 filtros, cada uno de 5x5.\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "# Se crea la capa de agrupamiento\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Se crea una capa que vuelva la imagen en un vector unidimensional para ser\n",
        "# pasado a red\n",
        "model.add(Flatten())\n",
        "# Se crea una capa oculta de 100 neuronas\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# Se crea la capa de salida con las 10 neuronas correspondientes a las\n",
        "# categorías, con función de activación softmax\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "# Se compila el modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Se entrena al modelo\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCGQXqrlOJQp",
        "outputId": "3b6ed5a6-74f9-4fa8-aff2-539de6448aba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.8590 - loss: 0.5105 - val_accuracy: 0.9772 - val_loss: 0.0740\n",
            "Epoch 2/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 97ms/step - accuracy: 0.9786 - loss: 0.0753 - val_accuracy: 0.9838 - val_loss: 0.0516\n",
            "Epoch 3/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - accuracy: 0.9859 - loss: 0.0485 - val_accuracy: 0.9857 - val_loss: 0.0434\n",
            "Epoch 4/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9884 - loss: 0.0373 - val_accuracy: 0.9863 - val_loss: 0.0433\n",
            "Epoch 5/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 102ms/step - accuracy: 0.9909 - loss: 0.0304 - val_accuracy: 0.9858 - val_loss: 0.0457\n",
            "Epoch 6/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - accuracy: 0.9941 - loss: 0.0207 - val_accuracy: 0.9871 - val_loss: 0.0411\n",
            "Epoch 7/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9934 - loss: 0.0192 - val_accuracy: 0.9868 - val_loss: 0.0413\n",
            "Epoch 8/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9955 - loss: 0.0154 - val_accuracy: 0.9876 - val_loss: 0.0388\n",
            "Epoch 9/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9884 - val_loss: 0.0402\n",
            "Epoch 10/10\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9979 - loss: 0.0081 - val_accuracy: 0.9880 - val_loss: 0.0409\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79877691eb00>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el modelo\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vRz4D3hPh8G",
        "outputId": "4258fb3c-6093-413a-8b61-4c9113059c0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 1.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales Recurrentes (RNN)\n",
        "Este tipo de redes toma la salida de una red junto a un peso como un dato de entrada para una segunda red, de tal forma que esta segunda red tiene su dato de entrada normal y, adicional, el dato de salida de la primer red. Así, la salida de la segunda red está influenciada por la primera. Esto es útil para aplicaciones donde el contexto es importante, por ejemplo, una escena de una video, en donde un fotograma tiene sentido respecto a los anteriores. Este tipo de redes son muy útiles modelando secuencias y patrones de datos, como textos, genomas, escritura a mano y mercados financieros. Un tipo de RNN muy popular es la llamada Long Short-term memory model (LSTM), que se usa para aplicaciones como:\n",
        "\n",
        " - Generación de imágenes\n",
        " - Escritura a mano\n",
        " - Reconocimiento de palabras en imágenes\n",
        " - Descripción automática de videos"
      ],
      "metadata": {
        "id": "a3Oe0Ky1XaHh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wp2QCVEaVqnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoders\n",
        "Estos son capaces de comprimir datos sin que les especifique cómo hacerlo. Estos son entrenados de forma no supervisada encontrando patrones utilizados para comprimir la información. Estos algoritmos son buenos comprimiendo únicamente información para la cual fueron entrenados, por lo tanto, uno que haya sido entrenado para comprimir imagenes de carros difícilmente podrá comprimir de forma correcta una imagen de una moto. Existen también los decoders, los cuales pueden tomar esta información comprimida y devolverla a su forma original.\n",
        "\n",
        "Un tipo popular de encoder es el Restricted Boltzmann Machines (RBMs). Este se utiliza para estimar datos faltantes de un conjunto de datos, balancear un conjunto de datos, y detectar características importante de un conjunto de datos."
      ],
      "metadata": {
        "id": "3fACl2NIbkrq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJk_jtJ9dAMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}